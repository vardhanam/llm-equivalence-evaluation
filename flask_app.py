from flask import Flask, request, jsonify
import os
from openai import OpenAI
import time
import ast

app = Flask(__name__)

# Set up the OpenAI API client
os.environ['OPENAI_API_KEY'] = 'YOUR_API_KEY'
client = OpenAI()

def get_text_from_image_url(image_url):
    """
    Extracts text from an image URL using the OpenAI API.

    Args:
        image_url (str): The URL of the image.

    Returns:
        str: The extracted text from the image.
    """
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "What's in this image?"},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": image_url,
                        },
                    },
                ],
            }
        ],
        max_tokens=300,
    )
    return response.choices[0].message.content

def get_prompt(conversation_history, user_response):
    """
    Generates a prompt for the LLM based on the conversation history and user response.

    Args:
        conversation_history (str): A string representation of the conversation history.
        user_response (str): The user's response to the final question.

    Returns:
        str: The generated prompt for the LLM.
    """
    prompt = "Below is a conversation history, a final question, and user response. Treat the conversation history as context, and check whether the user response is the correct answer to the final question. If it is correct then just return the word EQUIVALENT. If it is incorrect return the word NOT_EQUIVALENT. Do not return any other text.\n\n"
    prompt += "Conversation History:\n"

    # Convert the string representation of conversation history to a list of dictionaries
    conversation_history = ast.literal_eval(conversation_history)

    for i in range(len(conversation_history) - 1):
        message = conversation_history[i]
        if 'user' in message:
            user_msg = ""
            if isinstance(message['user'], list):
                for item in message['user']:
                    if item['type'] == 'text':
                        user_msg += item['text'] + ' '
                    elif item['type'] == 'image_url':
                        image_url = item['image_url']['url']
                        image_text = get_text_from_image_url(image_url)
                        user_msg += f"User provided image: {image_text} "
            else:
                user_msg = message['user']
            prompt += f"\tUser: {user_msg.strip()}\n"

        if 'bot' in message:
            prompt += f"\tBot: {message['bot']}\n"

    final_question = conversation_history[-1]['bot']
    prompt += f"\nFinal Question: {final_question}\n"
    prompt += f"User Response: {user_response}\n"

    return prompt

def get_llm_response(prompt):
    """
    Sends a prompt to the OpenAI API and retrieves the LLM response.

    Args:
        prompt (str): The prompt to send to the OpenAI API.

    Returns:
        tuple: A tuple containing the LLM response, time taken, and cost.
            - llm_response (str): The response generated by the LLM.
            - time_taken (float): The time taken (in seconds) to generate the response.
            - cost (float): The cost of generating the response.
    """
    try:
        start_time = time.time()
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ]
        )
        end_time = time.time()
        time_taken = end_time - start_time
        cost = response.usage.completion_tokens * 0.00003 + response.usage.prompt_tokens * 0.00001
        return response.choices[0].message.content, time_taken, cost
    except Exception as e:
        print(f"Error processing prompt: {e}")
        return None, None, None

@app.route('/evaluate', methods=['POST'])
def evaluate_equivalence():
    """
    API endpoint for evaluating the equivalence between user response and the correct answer.

    Request JSON format:
    {
        "conversation_history": "<string representation of conversation history>",
        "user_response": "<user's response to the final question>"
    }

    Response JSON format:
    {
        "llm_equivalence_evaluation": "<LLM equivalence evaluation response>",
        "time_taken": <time taken to complete the request in seconds>,
        "cost": <cost in dollars for the request>
    }
    """
    data = request.get_json()
    conversation_history = data['conversation_history']
    user_response = data['user_response']

    prompt = get_prompt(conversation_history, user_response)
    llm_response, time_taken, cost = get_llm_response(prompt)

    response = {
        'llm_equivalence_evaluation': llm_response,
        'time_taken': time_taken,
        'cost': cost
    }
    return jsonify(response)

if __name__ == '__main__':
    app.run()